# Seq imports
from bio import *

# Codon standard library imports
import sys
from threading import Lock
import openmp as omp
import datetime

# Python imports
from python import os, pickle, argparse, bz2, tqdm

# RDI imports
from archive import RdiArchive

INDEX_RDI_EXT = '.idx.rdi'

def write_index(index: Dict[int, Dict[int, List[int]]], file_path: str):
    print(f'Writing index to disk... ')
    archive = RdiArchive[Dict[int, Dict[int, List[int]]]]()
    archive.write(index, file_path, INDEX_RDI_EXT)

def load_index(file_path: str):
    print(f'Loading index from disk... ')
    archive = RdiArchive[Dict[int, Dict[int, List[int]]]]()
    return archive.load(file_path, INDEX_RDI_EXT)

# Generates a string repeat index, as well as a list of kmers
def repeat_detection_index(
    n: int,
    SA: List[Int[32]],
    LCP: List[Int],
    k: int,
    report: Callable[[List[Tuple[int, int, int]]], None]
):
    CHUNK_SIZE = 2 ** 12

    print("Building RDI dictionary.")
    progress = tqdm.tqdm(total=n, smoothing=0, colour='#1ED18B')

    @omp.critical
    def report_repeats(records: List[Tuple[int, int, int]]):
        # Call parent function
        report(records)
        progress.update(CHUNK_SIZE)
            
    # @par(schedule='dynamic', num_threads=2, ordered=True)
    for x in range(1, n + 1, CHUNK_SIZE):
        records = list()

        for i in range(x, min(x + CHUNK_SIZE - 1, n) + 1):
            if (LCP[i] < LCP[i + 1]):
                for k in range(LCP[i] + 1, LCP[i + 1] + 1):            
                    # Calculate j > i as the minimum value such that LCP[j] < LCP[i + 1]
                    j = i + 1
                    while j <= n + 1:
                        if (LCP[j] < k):
                            break
                        j += 1      

                    l: int = k      # Length of the string
                    r: int = j - i  # Number of occurrences
                    
                    records.append((i, l, r))

        report_repeats(records)

    progress.close()
    return


# TODO deprecating for now. Why? Because repeat_detection_index no longer
# returns a value; Any dictionaries or lists generated by
# repeat_detection_index will be consumed by the caller, via the passed
# report() callback.

# def load_or_generate_repeat_detection_index(
#     n: int,
#     SA: List[Int[32]],
#     LCP: List[Int],
#     k: int,
#     report: Callable[[List[Tuple[int, int, int]]], None],
#     file_path: Optional[str]
# ):    
#     if file_path is not None:
#         try:
#             # Check if RDI is already generated.
#             index = load_index(file_path)
#             print("[debug] Loaded repeat detection index and kmer counts from file successfully")
#             return index
        
#         except:
#             # Cannot read RDI from disk. Build the RDI.
#             print("[debug] Failed to load repeat detection index.")

#     index = _repeat_detection_index(n, SA, LCP, k, report)

#     if file_path is not None:
#         _write_index(index, file_path)
        
#     return index
