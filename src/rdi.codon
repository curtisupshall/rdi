from bio import *
from python import tqdm
from sa import build_suffix_array
from lcp import build_lcp_array
from index import repeat_detection_index
from kmer import get_read_indices_for_kmers
from anchor import get_read_indices_for_anchors
from tuples import Read
from genome import assemble_contigs

DEFAULT_KMER_SIZE = 12

class RepeatDetectonIndex:
    # The file path pointing to the FASTQ file
    __file_path: str
    
    # The suffix array
    __sa: List[Int[32]]
    
    # The LCP array
    __lcp: List[int]
    
    # The text, built from the reads in the FASTQ file
    __text: str
    
    # The length of the text
    __n: int
    
    # The size of the kmers that are recorded for assembly
    __k: int
    
    # The list of reads found in the FASTQ file
    __reads: List[Read]
    
    # `True` if checkpoints should be used, false otherwise
    __use_checkpoints: bool

    def __init__(self: RepeatDetectonIndex, file_path: str, use_checkpoints=True, k=DEFAULT_KMER_SIZE):
        self.__file_path = file_path
        self.__k = k
        self.__text = ''
        self.__n = 0
        self.__reads = List[Read]([])
        self.__use_checkpoints = use_checkpoints
        self.__sa = []
        self.__lcp = []
        
        self.__build_collection(file_path)
    
    def __build_collection(self: RepeatDetectonIndex, file_path: str):
        print("Reading file...")
        records: List[FASTQRecord] = [record for record in FASTQ(file_path)]

        progress = tqdm.tqdm(total=len(records), smoothing=0)

        for record in records:
            progress.update(1)
            self.__add_read(record)

        progress.close()    
        print(f'Building text for {str(len(self.__reads))} reads...')
        seqs = [str(read.record.seq).upper() for read in self.__reads]
        self.__text = '_'.join(seqs)
        
    def __assert_sa(self):
        if len(self.__sa) == 0:
            raise ValueError("Cannot build a repeat detection index with an empty suffix array.")

    def __assert_lcp(self):
        if len(self.__lcp) == 0:
            raise ValueError("Cannot build a repeat detection index with an empty LCP array.")
        
    def build_suffix_array(self):
        self.__sa = build_suffix_array(
            self.__text,
            self.__n,
            self.__file_path if self.__use_checkpoints else None
        )
        
    def build_lcp_array(self):
        self.__lcp = build_lcp_array(
            self.__text,
            self.__n,
            self.__sa,
            self.__file_path if self.__use_checkpoints else None
        )

    # Runs the repeat detection algorithm to retrieve kmer and anchor string
    # data, used to perform assembly
    def get_asm_data_by_rdi(
        self,
        length_range: Tuple[int, int],
        coverage_range: Tuple[int, int]
    ):
        self.__assert_sa()
        self.__assert_lcp()
        
        l_min, l_max = length_range
        c_min, c_max = coverage_range
        
        # A list of tuples representing candidate anchors. The first value
        # is the index in the suffix array table, the second value is the length of
        # the anchor, and the third value is the number of occurrences.
        candidate_anchors: List[Tuple[int, int, int]] = []

        # A list representing read kmers. Each kmer is represented by a tuple
        # whereby the first value is the index in the suffix array, and the
        # second value is the number of its occurrences.
        kmer_counts: List[Tuple[int, int]] = []

        def _report(records: List[Tuple[int, int, int]]):
            for record in records:
                i, l, r = record
                # p: int = int(self.__sa[i]) # Arbitrary appearance position in the text

                # Check if the record should be stored as a kmer
                if l == self.__k:
                    kmer_counts.append((i, r))

                # Check if the record should be stored as a candidate anchor
                if l_min <= l and l_max >= l and c_min <= r and c_max >= r:
                    candidate_anchors.append((i, l, r))

            return
        
        # Step 1. Run the RDI algroithm
        repeat_detection_index(
            self.__n,
            self.__sa,
            self.__lcp,
            self.__k,
            _report
        )
        
        # Step 2. Associate reads with kmers and anchor strings
        read_indices_for_kmers = get_read_indices_for_kmers(
            self.__sa,
            self.__reads,
            self.__k,
            kmer_counts
        )
        read_indices_for_anchors = get_read_indices_for_anchors(
            self.__sa,
            self.__reads,
            self.__k,
            candidate_anchors
        )
        
        # kmer_indices_total = sum(len(values) for values in read_indices_for_kmers.values())
        # print(f'kmer_indices_total: {kmer_indices_total}')
        # anchor_indices_total = sum(len(values) for values in read_indices_for_anchors.values())
        # print(f'anchor_indices_total: {anchor_indices_total}')

        # Step 3. Produce contigs
        # contig_bins = []
        for x, record in enumerate(self.__reads):
            if x not in read_indices_for_kmers:
                print(f"Could not find a kmer for read having index {str(x)}")
                
        contigs = assemble_contigs(
            self.__reads,
            candidate_anchors,
            read_indices_for_kmers,
            read_indices_for_anchors
        )

    # Returns a repeat detection index as a dictionary
    def build_repeat_detection_index(self):        
        self.__assert_sa()
        self.__assert_lcp()
        
        dictionary = Dict[int, Dict[int, List[int]]]()
        
        def _report(records: List[Tuple[int, int, int]]):
            for record in records:
                    i, l, r = record
                    p: int = int(self.__sa[i]) # Arbitrary appearance position in the text

                    if l not in dictionary:
                        dictionary[l] = dict()
                    if r not in dictionary[l]:
                        dictionary[l][r] = list()
                    dictionary[l][r].append(p)

        repeat_detection_index(
            self.__n,
            self.__sa,
            self.__lcp,
            self.__k,
            _report
        )
        
        return dictionary

    def __add_read(self, read: FASTQRecord):
        start_position = self.__n
        self.__n += len(read.seq) + 1
        self.__reads.append((start_position, read))
        return

    def __report_kmers(self, kmer_counts: List[Tuple[int, int]]):
        self.__assert_sa()
        
        pass
    
    def __report_anchor(self, p: int, l: int, r: int):
        pass
    
    def file_path(self) -> str:
        return self.__file_path
