from bio import *
from python import tqdm, json

import openmp as omp

from index import load_index
from archive import RdiArchive
from align import semiglobal

CANDIDATE_ANCHORS_RDI_EXT = '.cdt.rdi'

def generate_anchor_queries(coverage: int, lmin: int, lmax: int, a: int) -> List[Tuple[int, int]]:

    ls = [l for l in range(lmin, lmax + 1)]
    cs = [c for c in range(coverage - a, coverage + a + 1)]

    return [(l, c) for l in ls for c in cs]

def find_candidate_anchors(Text: str, coverage: int, lmin: int, lmax: int, a: int, file_path: str):
    Rdi = load_index(file_path)

    print("Generating anchor queries...")
    queries = generate_anchor_queries(coverage, lmin, lmax, a)
    
    print("Querying index for cadidate...")
    anchors = List[Tuple[int, int, int]]()
    progress = tqdm.tqdm(total=len(queries), smoothing=0)

    # @omp.critical
    def report(p: int, l: int, r: int):
        anchors.append((p, l, r))

    # @omp.critical
    def increment_progress():
        progress.update(1)

    # @par(schedule='static', chunk_size=100, num_threads=32, ordered=False)
    for l, r in queries:
        # Find candidate strings using index
        rs = Rdi[l] if l in Rdi else {}
        ps = rs[r] if r in rs else List[int]([])
        for p in ps:
            substring = Text[p:p+l]
            if ('_' in substring):
                continue
            report(p, l, r)
        increment_progress()

    progress.close()
    return anchors


# Loads a set of candidate anchors from disk
def load_candidate_anchors(file_path) -> List[Tuple[int, int, int]]:
    archive = RdiArchive[List[Tuple[int, int, int]]]()
    return archive.load(file_path, CANDIDATE_ANCHORS_RDI_EXT)

# Writes a set of candiate anchors to disk
def write_candidate_anchors(anchors, file_path):
    print('Saving candidate anchors to disk...')
    archive = RdiArchive[List[Tuple[int, int, int]]]()
    archive.write(anchors, file_path, CANDIDATE_ANCHORS_RDI_EXT)

def load_or_generate_candidate_anchors(Text: str, coverage: int, lmin: int, lmax: int, a: int, file_path: str, overwrite: bool = False):
    if not overwrite:
        try:
            # Check if candidate anchors are generated.
            anchors = load_candidate_anchors(file_path)
            print("[debug] Loaded candidate anchors from file successfully")
            return anchors

        except:
            # Cannot read anchors from disk. Build the anchor set.
            print("[debug] Failed to load candiate anchors.")

    anchors = find_candidate_anchors(Text, coverage, lmin, lmax, a, file_path)

    # Save the candidate anchors to disk
    write_candidate_anchors(anchors, file_path)

    return anchors

def find_reads_from_candidates(Text: str, anchors: List[Tuple[int, int, int]], file_path):
    print(f"Collecting reads from {str(len(anchors))} anchors...")
    anchor_reads = Dict[str, List[seq]]({})

    for (p, l, r) in anchors:
        anchor_sequence = Text[p:p+l]
        anchor_reads[anchor_sequence] = List[seq]([])

    # Iterate over reads
    for read in FASTQ(file_path):
        for anchor_sequence in anchor_reads:
            if (anchor_sequence in str(read.seq).upper()):
                anchor_reads[anchor_sequence].append(read.seq)

    # avg = 0

    # for x in anchor_reads:
    #     avg += len(anchor_reads[x])
    #     # print(f'{x}: {str(len(anchor_reads[x]))}')

    # print(f'Average read count: {str(avg / len(anchor_reads))}')
    return anchor_reads

def bin_reads(anchor_reads: Dict[str, List[seq]], alignment_threshold):
    print("Binning reads...")
    total_reads = sum(len(reads) for reads in anchor_reads.values())
    
    progress = tqdm.tqdm(total=total_reads, smoothing=0)

    contigs = List[List[seq]]()
    
    for anchor, reads in anchor_reads.items():
        for read in reads:
            if len(contigs) == 0:
                contigs.append(List[seq]([read]))
            else:
                for contig in contigs:
                    meets_threshold = True
                    for contig_read in contig:
                        score = semiglobal(str(read), str(contig_read))
                        if score > alignment_threshold:
                            meets_threshold = False
                            break
                    
                    if meets_threshold:
                        contig.append(read)
            progress.update(1)
    
    progress.close()
    return contigs
        
                

    
def perform_assembly(Text: str, file_path: str, coverage: int, lmin: int, lmax: int, a: int):
    anchors = load_or_generate_candidate_anchors(Text, coverage, lmin, lmax, a, file_path)
    anchor_reads = find_reads_from_candidates(Text, anchors, file_path)
    
    contigs = bin_reads(anchor_reads, 10)
    print(contigs)
    # for contig in contigs:
    #     for read in contig:
    #         semiglobal(str(read), str(contig[0]), True)
            
    #     break
