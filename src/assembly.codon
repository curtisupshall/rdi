from bio import *
from python import tqdm, json

import openmp as omp

from index import load_index
from archive import RdiArchive

CANDIDATE_ANCHORS_RDI_EXT = '.cdt.rdi'

def generate_anchor_queries(coverage: int, lmin: int, lmax: int, a: int) -> List[Tuple[int, int]]:

    ls = [l for l in range(lmin, lmax + 1)]
    cs = [c for c in range(coverage - a, coverage + a + 1)]

    return [(l, c) for l in ls for c in cs]

def find_candidate_anchors(Text: str, coverage: int, lmin: int, lmax: int, a: int, file_path: str):
    Rdi = load_index(file_path)

    print("Generating anchor queries...")
    queries = generate_anchor_queries(coverage, lmin, lmax, a)
    
    print("Querying index for cadidate...")
    anchors = List[Tuple[int, int, int]]()
    progress = tqdm.tqdm(total=len(queries), smoothing=0)

    # @omp.critical
    def report(p: int, l: int, r: int):
        anchors.append((p, l, r))

    # @omp.critical
    def increment_progress():
        progress.update(1)

    # @par(schedule='static', chunk_size=100, num_threads=32, ordered=False)
    for l, r in queries:
        # Find candidate strings using index
        rs = Rdi[l] if l in Rdi else {}
        ps = rs[r] if r in rs else List[int]([])
        for p in ps:
            substring = Text[p:p+l]
            if ('_' in substring):
                continue
            report(p, l, r)
        increment_progress()

    progress.close()
    return anchors


# Loads a set of candidate anchors from disk
def load_candidate_anchors(file_path) -> List[Tuple[int, int, int]]:
    archive = RdiArchive[List[Tuple[int, int, int]]]()
    return archive.load(file_path, CANDIDATE_ANCHORS_RDI_EXT)

# Writes a set of candiate anchors to disk
def write_candidate_anchors(anchors, file_path):
    print('Saving candidate anchors to disk...')
    archive = RdiArchive[List[Tuple[int, int, int]]]()
    archive.write(anchors, file_path, CANDIDATE_ANCHORS_RDI_EXT)

def load_or_generate_candidate_anchors(Text: str, coverage: int, lmin: int, lmax: int, a: int, file_path: str, overwrite: bool = False):
    if not overwrite:
        try:
            # Check if candidate anchors are generated.
            anchors = load_candidate_anchors(file_path)
            print("[debug] Loaded candidate anchors from file successfully")
            return anchors

        except:
            # Cannot read anchors from disk. Build the anchor set.
            print("[debug] Failed to load candiate anchors.")

    anchors = find_candidate_anchors(Text, coverage, lmin, lmax, a, file_path)

    # Save the candidate anchors to disk
    write_candidate_anchors(anchors, file_path)

    return anchors

def find_reads_from_candidates(Text: str, anchors: List[Tuple[int, int, int]], file_path):
    anchor_reads = Dict[str, List[str]]({})

    for (p, l, r) in anchors:
        anchor_sequence = Text[p:p+l]
        anchor_reads[anchor_sequence] = List[str]([])

    # Iterate over reads
    for read in FASTQ(file_path):
        read_sequence = str(read.seq).upper()
        for anchor_sequence in anchor_reads:
            if (anchor_sequence in read_sequence):
                anchor_reads[anchor_sequence].append(read_sequence)

    avg = 0

    for x in anchor_reads:
        avg += len(anchor_reads[x])
        # print(f'{x}: {str(len(anchor_reads[x]))}')

    print(f'Average read count: {str(avg / len(anchor_reads))}')
    
